# -*- coding: utf-8 -*-
"""Breastcancer_ANN

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R5EcDjnBSLPGNjoVBl1VdSipPAND8Weu
"""

pip install ucimlrepo

from ucimlrepo import fetch_ucirepo

# fetch dataset
breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)

# data (as pandas dataframes)
X = breast_cancer_wisconsin_diagnostic.data.features
y = breast_cancer_wisconsin_diagnostic.data.targets

# metadata
print(breast_cancer_wisconsin_diagnostic.metadata)

# variable information
print(breast_cancer_wisconsin_diagnostic.variables)

import numpy as np
import pandas as pd
from keras.models import Sequential
from keras.layers import Dense

url = "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data"
dataset = pd.read_csv(url, header=None)

dataset.columns = ['ID', 'Diagnosis', 'Mean Radius', 'Mean Texture', 'Mean Perimeter', 'Mean Area', 'Mean Smoothness', 'Mean Compactness', 'Mean Concavity', 'Mean Concave Points', 'Mean Symmetry', 'Mean Fractal Dimension', 'SE Radius', 'SE Texture', 'SE Perimeter', 'SE Area', 'SE Smoothness', 'SE Compactness', 'SE Concavity', 'SE Concave Points', 'SE Symmetry', 'SE Fractal Dimension', 'Worst Radius', 'Worst Texture', 'Worst Perimeter', 'Worst Area', 'Worst Smoothness', 'Worst Compactness', 'Worst Concavity', 'Worst Concave Points', 'Worst Symmetry', 'Worst Fractal Dimension']

dataset['Diagnosis'] = dataset['Diagnosis'].map({'M': 1, 'B': 0})

X = dataset.iloc[:, 2:].values
y = dataset.iloc[:, 1].values

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

print("X_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)
print("y_train shape:", y_train.shape)
print("y_test shape:", y_test.shape)

model = Sequential()
model.add(Dense(16, input_dim=30, activation='relu'))
model.add(Dense(8, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# Make predictions on the test data
y_pred = model.predict(X_test)

# Convert the probabilities to binary predictions
y_pred_binary = (y_pred > 0.5).astype(int)

# Print the binary predictions
print(y_pred_binary)

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

model.fit(X_train, y_train, epochs=100, batch_size=10)

_, accuracy = model.evaluate(X_test, y_test)
print('Accuracy: %.2f' % (accuracy*100))

model.summary()

import matplotlib.pyplot as plt

# Assuming you have already loaded and preprocessed the dataset
class_distribution = dataset['Diagnosis'].value_counts()
plt.bar(class_distribution.index, class_distribution.values)
plt.xlabel('Diagnosis')
plt.ylabel('Count')
plt.title('Class Distribution')
plt.show()

plt.hist(dataset['Mean Radius'], bins=20, color='skyblue', edgecolor='black')
plt.xlabel('Mean Radius')
plt.ylabel('Frequency')
plt.title('Distribution of Mean Radius')
plt.show()

plt.scatter(dataset['Mean Radius'], dataset['Mean Texture'], color='green')
plt.xlabel('Mean Radius')
plt.ylabel('Mean Texture')
plt.title('Mean Radius vs Mean Texture')
plt.show()

